{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d3392f-7471-4e5a-bebc-8664da78058e",
   "metadata": {},
   "source": [
    "# Exercise 3: ML Lifecycle Case Study\n",
    "\n",
    "[App8 Case Study](https://aws.amazon.com/solutions/case-studies/app-8/)\n",
    "\n",
    "Written response, select 3 of the 11 steps and write a short paragraph explaining how you would go about executing on these parts of the ML Lifecycle.\n",
    "\n",
    "Exact solutions will vary but should be somewhat related to the answers below.\n",
    "\n",
    "![ml-lifecycle.png](https://video.udacity-data.com/topher/2021/June/60c6cee3_ml-lifecycle/ml-lifecycle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fbd37f-46b0-474d-ad82-43b943198eb8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Data Gathering and Preprocessing:\n",
    "I would start by identifying the relevant data sources for predicting restaurant demand, such as historical sales data, weather data, social media trends, or even data from third-party food delivery services. Once the data sources are determined, I would gather the data and preprocess it to ensure its quality and suitability for the predictive model.\n",
    "\n",
    "### 2. Model Development and Training:\n",
    "I would explore various machine learning algorithms that can be used for demand prediction, such as regression models, time series analysis. Based on the problem at hand and the available data, I would select the most appropriate algorithm. Then, I would develop a training pipeline to feed the preprocessed data into the chosen algorithm. The model would be trained using historical data and optimized using techniques like cross-validation or hyperparameter tuning to ensure optimal performance. Iterative experimentation and evaluation would be conducted to select the best-performing model.\n",
    "\n",
    "### 3. Deployment and Monitoring:\n",
    "Once the predictive model is developed and trained, the next step is to deploy it to a production environment. In this phase, I would leverage AWS solutions, as mentioned in the case study, to host and serve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
